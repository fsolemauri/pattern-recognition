{"cells":[{"cell_type":"markdown","source":["<div style=\"width: 100%; clear: both;\">\n","<div style=\"float: left; width: 50%;\">\n","<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n","</div>\n","<div style=\"float: right; width: 50%;\">\n","<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M0.532 · Pattern Recognition</p>\n","<p style=\"margin: 0; text-align:right;\">Computational Engineering and Mathematics Master</p>\n","<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Computers, Multimedia and Telecommunications Department</p>\n","</div>\n","</div>\n","<div style=\"width:100%;\">&nbsp;</div>"],"metadata":{"id":"WltUPB9k7ScM"}},{"cell_type":"markdown","metadata":{"id":"ZAh07NuO35Nc"},"source":["In this notebook, we will see two different implementations of optical flow available in OpenCV. The first implementation is a sparse optical flow, which means that the optical flow is only computed for some pixels of the frames. The second implementation is a dense optical flow, which means that the optical flow is computed for all the pixels of the frames. Computing the optical flow can be useful for other video tasks such as object tracking or video object segmentation that we will see in the next notebooks. The code is based on [this tutorial](https://docs.opencv.org/4.x/d4/dee/tutorial_optical_flow.html)."]},{"cell_type":"markdown","metadata":{"id":"0JFkFX1FH1pJ"},"source":["#### Sparse Optical Flow"]},{"cell_type":"markdown","metadata":{"id":"lv-GQ1RV4Xih"},"source":["Let's start with the sparse optical flow implementation. We first download the video that we want to use for computing the optical flow."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2312,"status":"ok","timestamp":1639772353661,"user":{"displayName":"Carles Ventura","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhImvnSdfq8GVCeFZMwR3T0QjMyuAesBI1pc5H5Ng=s64","userId":"16735323099153148275"},"user_tz":-60},"id":"xVRaCTCsC7eM","outputId":"c6f2c265-6e64-447b-fc3e-323e1d003f62"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2021-12-17 20:19:11--  https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4\n","Resolving www.bogotobogo.com (www.bogotobogo.com)... 173.254.30.214\n","Connecting to www.bogotobogo.com (www.bogotobogo.com)|173.254.30.214|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2018126 (1.9M) [video/mp4]\n","Saving to: ‘slow_traffic_small.mp4’\n","\n","slow_traffic_small. 100%[===================>]   1.92M  1.75MB/s    in 1.1s    \n","\n","2021-12-17 20:19:13 (1.75 MB/s) - ‘slow_traffic_small.mp4’ saved [2018126/2018126]\n","\n"]}],"source":["!wget https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4"]},{"cell_type":"markdown","metadata":{"id":"51blaREH4w1T"},"source":["First, we open the video file with the VideoCapture function from OpenCV. Since this is an sparse implementation, we need to decide some local feature detection parameters that will be used such as the maximum number of keypoints (maxCorners) or the minumum distance between two keypoints detected (minDistance). We also need to define some parameters for computing the optical flow by using the Lucas Kanade algorithm, such as the winSize, which defines the neighbouring region around a keypoint considered to compute the optical flow, or the maxLevel, which allows to compute the optical flow at different image scales.\n","\n","The method is based on the detection of the local features by using the goodFeaturesToTrack function and then the computation of the optical flow by using the calcOpticalFlowPyrLK function."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"lpufiS8YFPSk","outputId":"ff016a53-494c-4123-aac2-10e372f7b0f9"},"outputs":[],"source":["import numpy as np\n","import cv2 as cv\n","from google.colab.patches import cv2_imshow\n","\n","cap = cv.VideoCapture('slow_traffic_small.mp4')\n","# params for ShiTomasi corner detection\n","feature_params = dict( maxCorners = 100,\n","                       qualityLevel = 0.3,\n","                       minDistance = 7,\n","                       blockSize = 7 )\n","# Parameters for lucas kanade optical flow\n","lk_params = dict( winSize  = (15, 15),\n","                  maxLevel = 2,\n","                  criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))\n","# Create some random colors\n","color = np.random.randint(0, 255, (100, 3))\n","# Take first frame and find corners in it\n","ret, old_frame = cap.read()\n","old_gray = cv.cvtColor(old_frame, cv.COLOR_BGR2GRAY)\n","p0 = cv.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n","# Create a mask image for drawing purposes\n","mask = np.zeros_like(old_frame)\n","while(1):\n","    ret, frame = cap.read()\n","    if not ret:\n","        print('No frames grabbed!')\n","        break\n","    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n","    # calculate optical flow\n","    p1, st, err = cv.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n","    # Select good points\n","    if p1 is not None:\n","        good_new = p1[st==1]\n","        good_old = p0[st==1]\n","    # draw the tracks\n","    for i, (new, old) in enumerate(zip(good_new, good_old)):\n","        a, b = new.ravel()\n","        c, d = old.ravel()\n","        mask = cv.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n","        frame = cv.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n","    img = cv.add(frame, mask)\n","    cv2_imshow(img)\n","    k = cv.waitKey(30) & 0xff\n","    if k == 27:\n","        break\n","    # Now update the previous frame and previous points\n","    old_gray = frame_gray.copy()\n","    p0 = good_new.reshape(-1, 1, 2)\n"]},{"cell_type":"markdown","metadata":{"id":"XVqLpdbRHnRs"},"source":["####Dense Optical Flow"]},{"cell_type":"markdown","metadata":{"id":"TCxxJ2R87yNy"},"source":["In order to compute the dense optical flow, we follow a similar implementation, with a few changes. We don't need to call the goodFeaturesToTrack function since we don't want to compute the optical flow based only on a few local features. Since we want to compute the optical flow for all the pixels of the frames, we will call the calcOpticalFlowFarneback function also available in OpenCV library. The color representation of the output in the HSV color space represents both the direction and the magnitude of the optical flow."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"nRcWEMMRHlij","outputId":"59b015e1-25a4-4f52-b3fd-f06168369f35"},"outputs":[],"source":["import numpy as np\n","import cv2 as cv\n","from google.colab.patches import cv2_imshow\n","cap = cv.VideoCapture('slow_traffic_small.mp4')\n","ret, frame1 = cap.read()\n","prvs = cv.cvtColor(frame1, cv.COLOR_BGR2GRAY)\n","hsv = np.zeros_like(frame1)\n","hsv[..., 1] = 255\n","while(1):\n","    ret, frame2 = cap.read()\n","    if not ret:\n","        print('No frames grabbed!')\n","        break\n","    next = cv.cvtColor(frame2, cv.COLOR_BGR2GRAY)\n","    flow = cv.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n","    mag, ang = cv.cartToPolar(flow[..., 0], flow[..., 1])\n","    hsv[..., 0] = ang*180/np.pi/2\n","    hsv[..., 2] = cv.normalize(mag, None, 0, 255, cv.NORM_MINMAX)\n","    bgr = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)\n","    cv2_imshow(bgr)\n","    k = cv.waitKey(30) & 0xff\n","    if k == 27:\n","        break\n","    elif k == ord('s'):\n","        cv.imwrite('opticalfb.png', frame2)\n","        cv.imwrite('opticalhsv.png', bgr)\n","    prvs = next\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"8_2_OpticalFlow_ClassicApproach.ipynb","provenance":[],"authorship_tag":"ABX9TyOz/MXZkP1byIEs3QuCkJzc"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}