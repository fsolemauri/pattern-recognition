{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.4_Content_based_image_retrieval.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"width: 100%; clear: both;\">\n",
        "<div style=\"float: left; width: 50%;\">\n",
        "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
        "</div>\n",
        "<div style=\"float: right; width: 50%;\">\n",
        "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M0.532 · Pattern Recognition</p>\n",
        "<p style=\"margin: 0; text-align:right;\">Computational Engineering and Mathematics Master</p>\n",
        "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Computers, Multimedia and Telecommunications Department</p>\n",
        "</div>\n",
        "</div>\n",
        "<div style=\"width:100%;\">&nbsp;</div>"
      ],
      "metadata": {
        "id": "lf9fpMypvVxQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Content based image retrieval"
      ],
      "metadata": {
        "id": "31XBlBUunEDb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w_ZG6KMXTTU"
      },
      "source": [
        "!pip install opencv-contrib-python==4.4.0.44"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM3DrWh2K7x1"
      },
      "source": [
        "from google.colab import drive\n",
        " \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls /content/drive/MyDrive/job\\ related/UOC/PDC\\ -\\ Classificació\\ Patrons/Reconeixement\\ de\\ Patrons/Notebooks/Tema\\ 5\\:\\ Image\\ Classification/101_ObjectCategories\n"
      ],
      "metadata": {
        "id": "LYKpjMbe7Jq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiM95D5pLSlD"
      },
      "source": [
        "from glob import glob\n",
        "from os.path import exists, isdir, basename, join, splitext\n",
        "\n",
        "datasetpath = '/content/drive/My Drive/Docència/Reconeixement de Patrons/Notebooks/Image Classification/101_ObjectCategories/'\n",
        "\n",
        "cat_paths = [files\n",
        "              for files in glob(datasetpath + \"/*\")\n",
        "              if isdir(files)]\n",
        "cat_paths.sort()\n",
        "cats = [basename(cat_path) for cat_path in cat_paths]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be using just a number of images and categories from the database to speed-up the execution"
      ],
      "metadata": {
        "id": "PZySvfqlHy_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_images_per_class = 20\n",
        "ncats = 50 #len(cats)\n",
        "\n",
        "print(cats)\n",
        "print(ncats)"
      ],
      "metadata": {
        "id": "-sFKsjakHzH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the dictionary"
      ],
      "metadata": {
        "id": "wyasYjHsRh7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract features\n",
        "\n",
        "We will use SIFT features as the previous examples. We encapsulate the code to extract the features of multiple images in the function extractSIFT"
      ],
      "metadata": {
        "id": "u6bCftkm_h3Y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG-Tpp6yFwJo"
      },
      "source": [
        "import cv2 as cv\n",
        "\n",
        "def extractSIFT(input_files):\n",
        "    \"\"\"\n",
        "    Extract SIFT features of a set of images. It returns a dictionary with the features of each image\n",
        "    \"\"\"\n",
        "    all_features_dict = {}\n",
        "    feature_extractor = cv.SIFT.create()\n",
        "    for i, fname in enumerate(input_files):\n",
        "        rgb = cv.cvtColor(cv.imread(fname), cv.COLOR_BGR2RGB)\n",
        "        gray = cv.cvtColor(rgb, cv.COLOR_RGB2GRAY)\n",
        "        kp, desc = feature_extractor.detectAndCompute(gray, None)\n",
        "        all_features_dict[fname] = desc\n",
        "    return all_features_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper function to get all the path of the images:"
      ],
      "metadata": {
        "id": "btn4RV8C_6mN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO9S2utgGI2C"
      },
      "source": [
        "EXTENSIONS = [\".jpg\", \".bmp\", \".png\", \".pgm\", \".tif\", \".tiff\"]\n",
        "\n",
        "def get_imgfiles(path):\n",
        "    \"\"\"\n",
        "    get imgfiles returns all the files with the defined extensions under a path\n",
        "    \"\"\"\n",
        "    all_files = []\n",
        "    all_files.extend([join(path, basename(fname))\n",
        "                    for fname in glob(path + \"/*\")\n",
        "                    if splitext(fname)[-1].lower() in EXTENSIONS])\n",
        "    return all_files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have defined the helper functions we can extract the features for all the images of the dataset:"
      ],
      "metadata": {
        "id": "YXaluKlFAOaX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYpAu5eyFIrB"
      },
      "source": [
        "all_files = []\n",
        "all_files_labels = {}\n",
        "all_features = {}\n",
        "cat_label = {}\n",
        "\n",
        "# for each category\n",
        "for cat, label in zip(cats, range(ncats)):\n",
        "    # generate the path for the category:\n",
        "    cat_path = join(datasetpath, cat)\n",
        "    # get all the files for the category:\n",
        "    cat_files = get_imgfiles(cat_path)\n",
        "\n",
        "    # we keep only a set of the images to speed-up the execution time:\n",
        "    cat_files = cat_files[:number_of_images_per_class]\n",
        "    print(\"label \" + str(label) + \": \" + cat)\n",
        "\n",
        "    # extract SIFT features:\n",
        "    cat_features = extractSIFT(cat_files)\n",
        "    # store the path for all files\n",
        "    all_files = all_files + cat_files\n",
        "    # save the features in the all_features dictionary:\n",
        "    all_features.update(cat_features)\n",
        "    # store the label for the category:\n",
        "    cat_label[cat] = label\n",
        "    for i in cat_files:\n",
        "        all_files_labels[i] = label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets analyse the features generated:"
      ],
      "metadata": {
        "id": "iTLvk7NpBvKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of images in the database = \" + str(len(all_features)) + \" images\")"
      ],
      "metadata": {
        "id": "tfD60qCLB0Gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all files has the path of each file, which is used as a key in the dictionary:\n",
        "file_path = all_files[0]\n",
        "# print the number of features of each image:\n",
        "print(\"First image has \" + str(len(all_features[file_path])) + \" SIFT descriptors\")\n",
        "print(\"Each descriptor has \" + str(len(all_features[file_path][0])) + \" features\")\n"
      ],
      "metadata": {
        "id": "kOsX3Gc0B0PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "count_features = 0\n",
        "all_features_list = []\n",
        "\n",
        "for key in all_features:\n",
        "#  print(key, '-', all_features[key])\n",
        "  count_features += len(all_features[key])\n",
        "  # generate a list from all the features\n",
        "  all_features_list.extend(all_features[key])\n",
        "\n",
        "print(count_features)\n",
        "print(len(all_features_list))\n",
        "\n",
        "# convert dictionary to a list of features:\n",
        "data = np.array(all_features_list)\n",
        "\n",
        "print(data.shape)\n",
        "\n",
        "print(\"We have \" + str(len(all_features)) + \" images in the database. \")\n",
        "print(\"The total number of descriptors for the images are \" + str(count_features) + \" (\" + str(round(count_features/len(all_features))) +\" descriptors per image).\")\n",
        "print(\"A brute force clustering to find similar images won't work.\")"
      ],
      "metadata": {
        "id": "yLiELGChtNt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cluster the features\n",
        "\n",
        "Once we have computed all the features we will build a dictionary to encode the features"
      ],
      "metadata": {
        "id": "pdF6hYs2QPBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# numbers of clusters (words) of our dictionary:\n",
        "numWords = 200\n"
      ],
      "metadata": {
        "id": "UcOBs5hxn6Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Cell does the cluster of features. It takes several minutes depending on the number of images selected ( 9 minuts with the default configuration)"
      ],
      "metadata": {
        "id": "iuN8luvxB_7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "kmeans_features = KMeans(n_clusters=numWords, random_state=0, n_init=5, max_iter=50).fit(data)\n"
      ],
      "metadata": {
        "id": "LWt7qPl5x9gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create an histogram of the features: "
      ],
      "metadata": {
        "id": "nBLYckaiQe3B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step we analyse again all the images: for each feature of each image we assign it to a word"
      ],
      "metadata": {
        "id": "TuCZy6yGQn6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate the histogram of features\n",
        "im_features = np.zeros((len(all_features), numWords), \"float32\")\n",
        "\n",
        "for ind, key in enumerate(all_features):\n",
        "\n",
        "  features_image = all_features[key]\n",
        "\n",
        "  labels = kmeans_features.predict(features_image)\n",
        "\n",
        "  # print(len(labels))\n",
        "\n",
        "  for label in labels: \n",
        "    im_features[ind][label] += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "w85PdCa8yOjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im_features"
      ],
      "metadata": {
        "id": "cDWVBmDY62AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets see one histogram generated "
      ],
      "metadata": {
        "id": "XOfynq7NP2ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# image index that we want to see the histogram:\n",
        "image_number = 117\n",
        "\n",
        "counts_, bins_, _ = plt.hist(im_features[image_number], bins=im_features[image_number].shape[0],\n",
        "                             weights=im_features[image_number], range=(0, len(im_features[image_number])))\n",
        "#plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "AIcbWxGUP3Dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the histogram: in the x axis we see the number of the word and in the y axis the occurrences of each word in the image"
      ],
      "metadata": {
        "id": "ncx1fESZQ30g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we will normalize the histogram (to compare images with different number of features):"
      ],
      "metadata": {
        "id": "aEmwvwxDRCOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "im_features = preprocessing.normalize(im_features, norm='l2')\n"
      ],
      "metadata": {
        "id": "ljpwJw6tnnjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(im_features_norm)"
      ],
      "metadata": {
        "id": "ltsQUjQP8Pqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the normalization we have finished the building of the dictionary. From now on we can extract similar images in the database given a query image!! "
      ],
      "metadata": {
        "id": "29hkW6U6ROVR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the algorithm: Extract similar images to a given example\n"
      ],
      "metadata": {
        "id": "2Dydw_KvTND4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select an image from the database:\n",
        "# image_path = all_files[95]\n",
        "\n",
        "# or select a random image from internet:\n",
        "image_path = \"image_query.jpg\"\n",
        "!wget http://www.sedaa.org/wp-content/uploads/2017/04/crocodile-875274_960_720.jpg -O image_query.jpg\n"
      ],
      "metadata": {
        "id": "4tm0Yvdu_io8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import argparse as ap\n",
        "import cv2\n",
        "import imutils \n",
        "import numpy as np\n",
        "import os\n",
        "# from sklearn.externals import joblib\n",
        "from scipy.cluster.vq import *\n",
        "\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "\n",
        "from pylab import *\n",
        "from PIL import Image\n",
        "\n",
        "# we will use the following import to display images in colab:\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# List where all the descriptors are stored\n",
        "des_list = []\n",
        "\n",
        "im = cv2.imread(image_path)\n",
        "print(image_path)\n",
        "\n",
        "cv2_imshow(im)\n"
      ],
      "metadata": {
        "id": "KPNDry0cTNO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets extract the features of the image:"
      ],
      "metadata": {
        "id": "7F3BCaq5SBwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor = cv.SIFT.create()\n",
        "\n",
        "\n",
        "# read image and extract features:\n",
        "rgb = cv.cvtColor(cv.imread(image_path), cv.COLOR_BGR2RGB)\n",
        "gray = cv.cvtColor(rgb, cv.COLOR_RGB2GRAY)\n",
        "kp, desc = feature_extractor.detectAndCompute(gray, None)\n"
      ],
      "metadata": {
        "id": "bjBsOAi8TNUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the histogram for the features:"
      ],
      "metadata": {
        "id": "SpCFkEi-SHuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "labels = kmeans_features.predict(desc)\n",
        "# labels = kmeans.predict(desc)\n",
        "\n",
        "\n",
        "query_image_features = np.zeros((numWords), \"float32\")\n",
        "\n",
        "for label in labels: \n",
        "  query_image_features[label] += 1\n",
        "\n",
        "# Perform Tf-Idf vectorization and L2 normalization\n",
        "# query_image_features = query_image_features*idf\n",
        "query_image_features = preprocessing.normalize([query_image_features], norm='l2')\n"
      ],
      "metadata": {
        "id": "Xln0IFUm4Lyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the histogram with all the histograms in the database:"
      ],
      "metadata": {
        "id": "8LZG0phWSOE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# the histograms are normalized, higher scores means that histograms are similar\n",
        "score = np.dot(query_image_features, im_features.T)\n",
        "# argsort sorts the scores from lower to higher. Since we are interested in higher scores we pass the negative scores:\n",
        "best_matches_sorted = np.argsort(-score)\n",
        "\n",
        "n_images_to_show = 5\n",
        "\n",
        "for num in range(n_images_to_show): \n",
        "\n",
        "\tselected_image = cv.imread(all_files[rank_ID[0][num]])\n",
        "\n",
        "\tcv2_imshow(selected_image)\n"
      ],
      "metadata": {
        "id": "LoKqaA48WUR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are obtaining images from the same category on the database and other images with similar colors and shapes!"
      ],
      "metadata": {
        "id": "9knlhRtcTSG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rhSNXh_sTaUy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}