{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.3_Feature_Matching.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"width: 100%; clear: both;\">\n",
        "<div style=\"float: left; width: 50%;\">\n",
        "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
        "</div>\n",
        "<div style=\"float: right; width: 50%;\">\n",
        "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M0.532 Â· Pattern Recognition</p>\n",
        "<p style=\"margin: 0; text-align:right;\">Computational Engineering and Mathematics Master</p>\n",
        "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Computers, Multimedia and Telecommunications Department</p>\n",
        "</div>\n",
        "</div>\n",
        "<div style=\"width:100%;\">&nbsp;</div>"
      ],
      "metadata": {
        "id": "lf9fpMypvVxQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Matching"
      ],
      "metadata": {
        "id": "rAqG_HhEnu_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this notebook we need to do the install of the contrib modules from OpenCV. Contrib contains patended algorithms and others under development. SIFT and ORB algorithms are in contrib module"
      ],
      "metadata": {
        "id": "fpxH6uC1Lvmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-contrib-python==4.4.0.44"
      ],
      "metadata": {
        "id": "QhvRxtx1Ltkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWz6Urycfq6C"
      },
      "source": [
        "# import OpenCV library\n",
        "import cv2\n",
        "\n",
        "# we will use the following import to display images in colab:\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNP3NtFBfggJ"
      },
      "source": [
        "!wget https://github.com/opencv/opencv/blob/master/samples/data/leuvenA.jpg?raw=true -O leuvenA.jpg\n",
        "!wget https://github.com/opencv/opencv/blob/master/samples/data/leuvenB.jpg?raw=true -O leuvenB.jpg\n",
        "\n",
        "# read image\n",
        "img1 = cv2.imread('leuvenA.jpg', cv2.IMREAD_COLOR)\n",
        "img2 = cv2.imread('leuvenB.jpg', cv2.IMREAD_COLOR)\n",
        "\n",
        "# convert image to grayscale\n",
        "img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(cv2.hconcat([img1, img2]))"
      ],
      "metadata": {
        "id": "gQeum9Vc0sp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets initiate SIFT Detector and use it with both images:"
      ],
      "metadata": {
        "id": "UDBEvTg22nHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiate SIFT detector\n",
        "sift = cv2.xfeatures2d.SIFT_create()\n",
        "\n",
        "# find the keypoints and descriptors with ORB\n",
        "kp1, des1 = sift.detectAndCompute(img1,None)\n",
        "kp2, des2 = sift.detectAndCompute(img2,None)"
      ],
      "metadata": {
        "id": "fTJT6ot7zEZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And plot the keypoints (same than feature detection):"
      ],
      "metadata": {
        "id": "xax1GKOgN6P0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img1_sift = np.empty((img1.shape[0], img1.shape[1], 3), dtype=np.uint8)\n",
        "img1_sift = cv2.drawKeypoints(img1, kp1, img1_sift)\n",
        "\n",
        "img2_sift = np.empty((img2.shape[0], img2.shape[1], 3), dtype=np.uint8)\n",
        "img2_sift = cv2.drawKeypoints(img2, kp1, img2_sift)"
      ],
      "metadata": {
        "id": "SzPXvN6FNZ6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(cv2.hconcat([img1_sift, img2_sift]))"
      ],
      "metadata": {
        "id": "MYPD2DdENlj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have the features for both image we can start the feature matching"
      ],
      "metadata": {
        "id": "H1IBMWbf3PjF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Brute force"
      ],
      "metadata": {
        "id": "STgQzN793XCA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets do the matching with [BFMatcher](https://docs.opencv.org/4.5.4/d3/da1/classcv_1_1BFMatcher.html).\n",
        "\n",
        "With BFMatcher.knnMatch() we get the k best matches. The algorithm takes the descriptor of one feature in the first image and compares it with all the features of the second image. The closest value (we have to define a distance measure also) is returned.\n"
      ],
      "metadata": {
        "id": "Q64-llXw3fMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BFMatcher with default params\n",
        "bf = cv2.BFMatcher()\n",
        "matches = bf.match(des1,des2)"
      ],
      "metadata": {
        "id": "i7jFkgKlzT2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Draw](https://docs.opencv.org/4.x/d4/d5d/group__features2d__draw.html) all matches between images:"
      ],
      "metadata": {
        "id": "6OtoKFSi6vdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img3 = cv2.drawMatches(img1,kp1,img2,kp2,matches,None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)"
      ],
      "metadata": {
        "id": "dlKrVYM56r8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(img3)"
      ],
      "metadata": {
        "id": "0Dbl1uF0zf0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are too many matches to see if the matching algorithm works well, lets try to keep only some matches (keep the best ones):\n",
        "\n",
        "matches returned from the algorithm are a [DMatch Object](https://docs.opencv.org/3.4/d4/de0/classcv_1_1DMatch.html)"
      ],
      "metadata": {
        "id": "1Ty7sicM69x1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the matches with the distance parameter of matches\n",
        "matches = sorted(matches, key = lambda x:x.distance)\n",
        "\n",
        "# Draw first 50 matches.\n",
        "img3 = cv2.drawMatches(img1,kp1,img2,kp2,matches[:50],None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)"
      ],
      "metadata": {
        "id": "GDmXbN1S6rHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(img3)"
      ],
      "metadata": {
        "id": "m098qhwgzZc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best matches found by the algorithm looks mostly good. Not all the correspondences obtained are perfect but errors are in the neighborhod of the correct point"
      ],
      "metadata": {
        "id": "xvpZ-zOi8ceZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Efficient matching"
      ],
      "metadata": {
        "id": "XwpzLmfF8w8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous example we used a brute force implementation. Brute force is not feasible when working with large datasets. \n",
        "\n",
        "An algorithm for efficient matchin is FLANN (Fast Library for Approximate Nearest Neighbors). With FLANN we can compute the best matches in an optimized way, resulting in significant reductions on the computing time compared to BFMatcher"
      ],
      "metadata": {
        "id": "9NbzwP76-2Ae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[FLANN](https://docs.opencv.org/4.x/dc/de2/classcv_1_1FlannBasedMatcher.html) needs as input a dictionary with the rellevant parameters for the matching search. We will use the same configuration than in the documentation [example](https://docs.opencv.org/4.x/dc/dc3/tutorial_py_matcher.html): "
      ],
      "metadata": {
        "id": "-XK0sKjP_8Zx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FLANN parameters\n",
        "FLANN_INDEX_KDTREE = 1\n",
        "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
        "search_params = dict(checks=50)   # or pass empty dictionary\n",
        "flann = cv2.FlannBasedMatcher(index_params,search_params)"
      ],
      "metadata": {
        "id": "FC7HPJ3Z-1Qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets compute the matches:"
      ],
      "metadata": {
        "id": "diiVedeyCHVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matches = flann.match(des1,des2)\n"
      ],
      "metadata": {
        "id": "ptq28WPD82Br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets keep only the best matches:"
      ],
      "metadata": {
        "id": "xcAJfiMLCK1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the matches with the distance parameter of matches\n",
        "matches = sorted(matches, key = lambda x:x.distance)\n",
        "\n",
        "# Draw first 50 matches.\n",
        "img3 = cv2.drawMatches(img1,kp1,img2,kp2,matches[:50],None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)"
      ],
      "metadata": {
        "id": "U9aDjca8B95Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(img3)"
      ],
      "metadata": {
        "id": "kjRBMIRFBTrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results is similar than the one obtained with BFMatcher. Lets see if this algorithm is more efficient. We can install autotime that will tell the execution time of each cell:"
      ],
      "metadata": {
        "id": "d-Vk1qFXCTC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipython-autotime\n",
        "\n",
        "%load_ext autotime\n"
      ],
      "metadata": {
        "id": "zGD2vFCvCSFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matches = bf.match(des1,des2)"
      ],
      "metadata": {
        "id": "c0oL6o6kB5Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matches = flann.match(des1,des2)\n"
      ],
      "metadata": {
        "id": "g_2vVRzMCyWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The computation time of flann is 40% lower than the bfmatcher!"
      ],
      "metadata": {
        "id": "2FG3WFKfC9pd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QN4KCpx-C8HR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}