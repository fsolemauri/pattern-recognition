{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"width: 100%; clear: both;\">\n",
        "<div style=\"float: left; width: 50%;\">\n",
        "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
        "</div>\n",
        "<div style=\"float: right; width: 50%;\">\n",
        "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M0.532 Â· Pattern Recognition</p>\n",
        "<p style=\"margin: 0; text-align:right;\">Computational Engineering and Mathematics Master</p>\n",
        "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Computers, Multimedia and Telecommunications Department</p>\n",
        "</div>\n",
        "</div>\n",
        "<div style=\"width:100%;\">&nbsp;</div>"
      ],
      "metadata": {
        "id": "-gtnaVGOmCL3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXrKzKGNVGEW"
      },
      "source": [
        "Reference Notebook: <br>\n",
        "\n",
        "https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/vision/ipynb/autoencoder.ipynb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TxQJwmzTOIB"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm8DRTwwW1rv"
      },
      "source": [
        "Do all the imports needed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EERiRpDpTOIC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYj7OaENW8dP"
      },
      "source": [
        "Lets define functions to preprocess input data and to display images "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdvTW9ttWxt0"
      },
      "outputs": [],
      "source": [
        "def preprocess(array):\n",
        "    \"\"\"\n",
        "    Normalizes the supplied array and reshapes it into the appropriate format.\n",
        "    \"\"\"\n",
        "\n",
        "    array = array.astype(\"float32\") / 255.0\n",
        "    array = np.reshape(array, (len(array), 28, 28, 1))\n",
        "    return array\n",
        "\n",
        "def display_array(array):\n",
        "    \"\"\"\n",
        "    Displays ten random images from the supplied array.\n",
        "    \"\"\"\n",
        "\n",
        "    n = 10\n",
        "\n",
        "    indices = np.random.randint(len(array), size=n)\n",
        "    images = array[indices, :]\n",
        "\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i, image in enumerate(images):\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(image.reshape(28, 28))\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def display_arrays(array1, array2):\n",
        "    \"\"\"\n",
        "    Displays ten random images from each one of the supplied arrays.\n",
        "    \"\"\"\n",
        "\n",
        "    n = 10\n",
        "\n",
        "    indices = np.random.randint(len(array1), size=n)\n",
        "    images1 = array1[indices, :]\n",
        "    images2 = array2[indices, :]\n",
        "\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i, (image1, image2) in enumerate(zip(images1, images2)):\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(image1.reshape(28, 28))\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(image2.reshape(28, 28))\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH269ofNTOID"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH7CJluWXF6j"
      },
      "source": [
        "Lets load mnist data, preprocess it with the function defined above and display the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bhy9afGCTOIE"
      },
      "outputs": [],
      "source": [
        "# Since we only need images from the dataset to encode and decode, we\n",
        "# won't use the labels.\n",
        "(train_data, _), (test_data, _) = mnist.load_data()\n",
        "\n",
        "# Normalize and reshape the data\n",
        "train_data = preprocess(train_data)\n",
        "test_data = preprocess(test_data)\n",
        "\n",
        "# Display the train data and a version of it with added noise\n",
        "display_array(train_data) # , noisy_train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK30Ips1TOIE"
      },
      "source": [
        "## Build the autoencoder\n",
        "\n",
        "We are going to use the Functional API to build our convolutional autoencoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NK9-ktkmTOIF"
      },
      "outputs": [],
      "source": [
        "input = layers.Input(shape=(28, 28, 1))\n",
        "\n",
        "# Encoder\n",
        "\n",
        "# convolutional layer (trainable parameters)\n",
        "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input)\n",
        "# max pooling: we reduce the output of the layer to (14, 14):\n",
        "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
        "# convolutional layer (trainable parameters)\n",
        "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
        "# max pooling: we reduce the output of the layer to (7, 7):\n",
        "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
        "\n",
        "\n",
        "# Decoder\n",
        "# the input of the decoder has a shape of (7, 7, 32)\n",
        "# notice that with the Conv2DTranspose we are increasing the rows and cols:\n",
        "# https://keras.io/api/layers/convolution_layers/convolution2d_transpose/\n",
        "# we are creating 32 filters, with kernels 3x3 and stride 2\n",
        "# the output of the layer is of size (14, 14, 32)\n",
        "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "# with the following Conv2D the output of the layer is of size (28, 28, 32)\n",
        "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "# last layer generates an output of size (28, 28, 1): the same size of the input!\n",
        "x = layers.Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAUQT5nQbwIU"
      },
      "outputs": [],
      "source": [
        "# lets define the Autoencoder:\n",
        "autoencoder = Model(input, x)\n",
        "autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwiUmvpgTOIG"
      },
      "source": [
        "Now we can train our autoencoder using `train_data` as both our input data\n",
        "and target. Notice we are setting up the validation data using the same\n",
        "format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOtjnpQJTOIG"
      },
      "outputs": [],
      "source": [
        "autoencoder.fit(\n",
        "    x=train_data,\n",
        "    y=train_data,\n",
        "    epochs=50,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    validation_data=(test_data, test_data),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt-Ph2YcTOIH"
      },
      "source": [
        "Let's predict on our test dataset and display the original image together with\n",
        "the prediction from our autoencoder.\n",
        "\n",
        "Notice how the predictions are pretty close to the original images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIhFCtanTOIH"
      },
      "outputs": [],
      "source": [
        "predictions = autoencoder.predict(test_data)\n",
        "display(test_data, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYck9V6Nd0cb"
      },
      "source": [
        "The autoencoder have been able to reconstruct the input images. Optional exercice: modify the autoencoder to obtain a latent space with less dimensions until the quality of the images starts to degrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPEkoHgbtik6"
      },
      "source": [
        "Also you can see an application of autoencoders: remove noise\n",
        "\n",
        "\n",
        "https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/vision/ipynb/autoencoder.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHqQGs-5V-NR"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "1_Autoencoders.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}