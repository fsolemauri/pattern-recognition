{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"width: 100%; clear: both;\">\n",
        "<div style=\"float: left; width: 50%;\">\n",
        "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
        "</div>\n",
        "<div style=\"float: right; width: 50%;\">\n",
        "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M0.532 · Pattern Recognition</p>\n",
        "<p style=\"margin: 0; text-align:right;\">Computational Engineering and Mathematics Master</p>\n",
        "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Computers, Multimedia and Telecommunications Department</p>\n",
        "</div>\n",
        "</div>\n",
        "<div style=\"width:100%;\">&nbsp;</div>"
      ],
      "metadata": {
        "id": "lf9fpMypvVxQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi_mltshF-K4"
      },
      "source": [
        "# Non linear filtering\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu_A1e4BG8s_"
      },
      "source": [
        "# import OpenCV library\n",
        "import cv2\n",
        "\n",
        "# we will use the following import to display images in colab:\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# we will use numpy to generate the kernel\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1-hODkZG_ht"
      },
      "source": [
        "!wget https://github.com/opencv/opencv/blob/master/samples/data/baboon.jpg?raw=true -O baboon.jpg\n",
        "\n",
        "#read image\n",
        "img_gray = cv2.imread('baboon.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "img = cv2.imread('baboon.jpg', cv2.IMREAD_COLOR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF_NqXMpGIpq"
      },
      "source": [
        "## Median filter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvuXmfcIJ5Cm"
      },
      "source": [
        "Median filtering selects the median value from each pixel’s neighborhood. It is used to remove salt and pepper noise (noise that takes extreme white or black values in certain pixels in the image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvLr4xKXMDgN"
      },
      "source": [
        "### Adding salt and pepper noise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDA1pPnMMMGc"
      },
      "source": [
        "We take a [function](https://stackoverflow.com/questions/22937589/how-to-add-noise-gaussian-salt-and-pepper-etc-to-image-in-python-with-opencv) to generate salt and pepper noise:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6JDvR7rMGZ-"
      },
      "source": [
        "def noisy(noise_typ,image):\n",
        "\n",
        "  '''\n",
        "  image : ndarray\n",
        "      Input image data. Will be converted to float.\n",
        "  mode : str\n",
        "      One of the following strings, selecting the type of noise to add:\n",
        "\n",
        "      'gauss'     Gaussian-distributed additive noise.\n",
        "      'poisson'   Poisson-distributed noise generated from the data.\n",
        "      's&p'       Replaces random pixels with 0 or 1.\n",
        "      'speckle'   Multiplicative noise using out = image + n*image,where\n",
        "                  n is uniform noise with specified mean & variance.\n",
        "  '''\n",
        "\n",
        "  if noise_typ == \"gauss\":\n",
        "    row,col,ch= image.shape\n",
        "    mean = 0\n",
        "    var = 0.1\n",
        "    sigma = var**0.5\n",
        "    gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
        "    gauss = gauss.reshape(row,col,ch)\n",
        "    noisy = image + gauss\n",
        "    return noisy\n",
        "\n",
        "  elif noise_typ == \"s&p\":\n",
        "    row,col,ch = image.shape\n",
        "    s_vs_p = 0.5\n",
        "    amount = 0.004\n",
        "    out = np.copy(image)\n",
        "\n",
        "    # Salt mode\n",
        "    num_salt = int(np.ceil(amount * image.size * s_vs_p))\n",
        "\n",
        "    # image salted\n",
        "    for i in range(0, num_salt):\n",
        "        row = np.random.randint(0, image.shape[0])\n",
        "        col = np.random.randint(0, image.shape[1])\n",
        "        out[row, col, :] = 255\n",
        "\n",
        "    # Pepper mode\n",
        "    num_pepper = int(np.ceil(amount* image.size * (1. - s_vs_p)))\n",
        "\n",
        "    # image peppered\n",
        "    for i in range(0,num_pepper):\n",
        "        row = np.random.randint(0, image.shape[0])\n",
        "        col = np.random.randint(0, image.shape[1])\n",
        "        out[row, col, :] = 0\n",
        "\n",
        "    return out\n",
        "\n",
        "  elif noise_typ == \"poisson\":\n",
        "    vals = len(np.unique(image))\n",
        "    vals = 2 ** np.ceil(np.log2(vals))\n",
        "    noisy = np.random.poisson(image * vals) / float(vals)\n",
        "    return noisy\n",
        "\n",
        "  elif noise_typ ==\"speckle\":\n",
        "    row,col,ch = image.shape\n",
        "    gauss = np.random.randn(row,col,ch)\n",
        "    gauss = gauss.reshape(row,col,ch)\n",
        "    noisy = image + image * gauss\n",
        "    return noisy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFMoXsv_MwxD"
      },
      "source": [
        "img_with_noise = noisy(\"s&p\", img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEYuiLm_NfUi"
      },
      "source": [
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjE9mF6tNiWB"
      },
      "source": [
        "cv2_imshow(img_with_noise)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOZVbp0ePVL9"
      },
      "source": [
        "Since we are doing the examples with gray images, lets transform the image to gray with the [cvtColor](https://docs.opencv.org/4.5.4/d8/d01/group__imgproc__color__conversions.html#ga397ae87e1288a81d2363b61574eb8cab) function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmctELwcOAtD"
      },
      "source": [
        " img_with_noise_gray = cv2.cvtColor(img_with_noise, cv2.COLOR_RGB2GRAY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znh3_4HMOK9F"
      },
      "source": [
        "cv2_imshow(img_with_noise_gray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCz8T6c2Pu8q"
      },
      "source": [
        "### Remove noise with median filter:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0HNW2D4Pziu"
      },
      "source": [
        "Use the [medianBlur](https://docs.opencv.org/4.5.4/d4/d86/group__imgproc__filter.html#ga564869aa33e58769b4469101aac458f9) function from Opencv. It has as a parameter the aperture size; it must be odd and greater than 1 (3, 5, 7 , ...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIKqBgcsJRdU"
      },
      "source": [
        "\n",
        "aperture_size = 5\n",
        "\n",
        "median = cv2.medianBlur(img_with_noise_gray, aperture_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcTchNZOOSiy"
      },
      "source": [
        "cv2_imshow(median)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__DBImPHgWna"
      },
      "source": [
        "## Bilateral filter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylj6t00mhP-L"
      },
      "source": [
        "Similarly at the median filtering, Owe can do the bilateral filtering with OpenCV. Bilateral filter is a filter to reduce noise while trying to preserve the edges sharp).\n",
        "\n",
        "\n",
        "Looking at the documentation:\n",
        "\n",
        "https://docs.opencv.org/4.5.4/d4/d86/group__imgproc__filter.html#ga9d7064d478c95d60003cf839430737ed\n",
        "\n",
        "\n",
        "Python:\n",
        "\n",
        "    cv.bilateralFilter(\tsrc, d, sigmaColor, sigmaSpace[, dst[, borderType]]\t) ->\tdst\n",
        "\n",
        "\n",
        "**d**\tDiameter of each pixel neighborhood that is used during filtering.\n",
        "\n",
        "**Sigma values**: For simplicity, you can set the 2 sigma values to be the same. If they are small (< 10), the filter will not have much effect, whereas if they are large (> 150), they will have a very strong effect, making the image look \"cartoonish\".\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3xkfog8gW9i"
      },
      "source": [
        "d_bilateral = 7\n",
        "sigma_bilateral = 70\n",
        "\n",
        "img_bilateral = cv2.bilateralFilter(img_with_noise_gray, d_bilateral, sigma_bilateral, sigma_bilateral)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTvixeZLhO8u"
      },
      "source": [
        "cv2_imshow(img_bilateral)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM-Yx1sLOnU1"
      },
      "source": [
        "Can you distinguish the results of the median filter from the bilateral one? Which one is better? Test with different parameters for each filter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPit1lT0Hzko"
      },
      "source": [
        "## Connected components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNTFgnxvVJeK"
      },
      "source": [
        "Connected components are defined as regions of adjacent pixels that have the same input value or label. It works with binary images. To do so we first will binarize the image (using thresholding)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtZS7AiqSZsa"
      },
      "source": [
        "Lets load a suitable image for the analysis and [binarize](https://docs.opencv.org/4.5.4/d7/d1b/group__imgproc__misc.html#gae8a4a146d1ca78c626a53577199e9c57) it to do the example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3H_1T_nH1Yl"
      },
      "source": [
        "!wget https://github.com/opencv/opencv/blob/master/samples/data/pic3.png?raw=true -O pic3.png\n",
        "\n",
        "# read image\n",
        "img = cv2.imread('pic3.png', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# and convert to binary (pixels lower to 200 set to 0, and the others to 255):\n",
        "img = cv2.threshold(img, 200, 255, cv2.THRESH_BINARY)[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsLX_UKiShGR"
      },
      "source": [
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhYDXNdBV1mU"
      },
      "source": [
        "We can see that there are 4 shapes drawn in the image!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfzJqrQ3WWns"
      },
      "source": [
        "The [connected components](https://docs.opencv.org/4.5.4/d3/dc0/group__imgproc__shape.html#gaedef8c7340499ca391d459122e51bef5) function computes the connected components labeled image of boolean image\n",
        "\n",
        "Python:\n",
        "  >  cv.connectedComponents(\timage[, labels[, connectivity[, ltype]]]\t) ->\tretval, labels\n",
        "\n",
        " returns\n",
        "   > retval: the total number of labels [0, N-1] where 0 represents the background label.\n",
        "   \n",
        "   > labels: the resulting label of each pixel in the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJn60NOZSi42"
      },
      "source": [
        "num_labels, labels = cv2.connectedComponents(img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7xi7LlsS32x"
      },
      "source": [
        "print(num_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoL7bLdbXinC"
      },
      "source": [
        "This result indicates that we have 6 connected labels (background + 5 regions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqpn-naYUBx7"
      },
      "source": [
        "\n",
        "def imshow_connected_components(labels):\n",
        "\n",
        "    # Map component labels to distinct colors (hsv):\n",
        "    label_hue = np.uint8(179*labels/np.max(labels))\n",
        "    blank_ch = 255*np.ones_like(label_hue)\n",
        "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
        "\n",
        "    # cvt to BGR for display\n",
        "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "    # set background label to black\n",
        "    labeled_img[label_hue==0] = 0\n",
        "\n",
        "    cv2_imshow(labeled_img)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rv2s-qDUWXf"
      },
      "source": [
        "imshow_connected_components(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayEuwiHZYM44"
      },
      "source": [
        "See that the background areas separate the other regions!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJRbruuLZ-a2"
      },
      "source": [
        "### Distance transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZjAP333aCTw"
      },
      "source": [
        "The distance transform is another binary image processing technique useful in quickly precomputing the distance to a curve. We can follow with the same image that we worked in the previous example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t73A3VOcaTmo"
      },
      "source": [
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLSuU4rWaaRO"
      },
      "source": [
        "The [distance transform](https://docs.opencv.org/4.5.4/d7/d1b/group__imgproc__misc.html#ga8a0b7fdfcb7a13dde018988ba3a43042) Calculates the distance to the closest zero pixel for each pixel of the source image:\n",
        "\n",
        "Python:\n",
        "> cv.distanceTransform(\tsrc, distanceType, maskSize[, dst[, dstType]]\t) ->\tdst\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJID0vUhUbSs"
      },
      "source": [
        "# Perform the distance transform algorithm\n",
        "\n",
        "# distance_type: the simple euclidean distance\n",
        "distance_type = cv2.DIST_L2\n",
        "mask_size = 3\n",
        "dist = cv2.distanceTransform(img, distance_type, mask_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wneEG6YhbrGK"
      },
      "source": [
        "# Normalize the distance image for range = {0.0, 1.0}\n",
        "# so we can visualize and threshold it\n",
        "cv2.normalize(dist, dist, 0, 255, cv2.NORM_MINMAX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXls_-6zbPwY"
      },
      "source": [
        "cv2_imshow(dist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghVEBQAZcls9"
      },
      "source": [
        "We can see that we have obtained the distance to background pixels. Whiter pixels are further from the background than the others"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9iUw0jqbXf0"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}